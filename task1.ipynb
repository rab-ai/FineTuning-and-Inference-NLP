{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import transformers\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "MAX_LENGTH = 128\n",
    "TRAIN_TEST_SPLIT_RATIO = 0.1\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(filepath, drop_na=True):\n",
    "    \"\"\"Loads data, checks for missing values, and optionally drops missing rows.\"\"\"\n",
    "    data = pd.read_csv(filepath, sep='\\t')\n",
    "    print(f\"Dataset Statistics for {filepath}:\")\n",
    "    print(data['label'].value_counts(normalize=True))\n",
    "    print(f\"Missing Value Check for {filepath}:\")\n",
    "    print(data.isnull().sum())\n",
    "    if drop_na:\n",
    "        data = data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(data, test_size=TRAIN_TEST_SPLIT_RATIO, random_state=RANDOM_STATE):\n",
    "    \"\"\"Splits the dataset into training and test sets with stratification.\"\"\"\n",
    "    train, test = train_test_split(\n",
    "        data,\n",
    "        test_size=test_size,\n",
    "        stratify=data['label'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    print(\"Class Distribution in Training Set:\")\n",
    "    print(train['label'].value_counts(normalize=True))\n",
    "    print(\"Class Distribution in Test Set:\")\n",
    "    print(test['label'].value_counts(normalize=True))\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_datasets(train, test, train_filepath, test_filepath):\n",
    "    \"\"\"Saves the training and test sets to CSV files.\"\"\"\n",
    "    train.to_csv(train_filepath, index=False)\n",
    "    test.to_csv(test_filepath, index=False)\n",
    "    print(f\"Saved training set to {train_filepath}\")\n",
    "    print(f\"Saved test set to {test_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets_for_training(train_data, test_data, tokenizer):\n",
    "    \"\"\"Tokenizes the data and prepares it for training.\"\"\"\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_data).map(tokenize_function, batched=True)\n",
    "    test_dataset = Dataset.from_pandas(test_data).map(tokenize_function, batched=True)\n",
    "\n",
    "    train_dataset = train_dataset.remove_columns([\"id\", \"speaker\", \"sex\", \"text\", \"text_en\"])\n",
    "    test_dataset = test_dataset.remove_columns([\"id\", \"speaker\", \"sex\", \"text\", \"text_en\"])\n",
    "\n",
    "    train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "    test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "    train_dataset.set_format(\"torch\")\n",
    "    test_dataset.set_format(\"torch\")\n",
    "\n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataset, test_dataset, tokenizer):\n",
    "    \"\"\"Trains a BERT model and evaluates it.\"\"\"\n",
    "    model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results_task1\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=50\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    results = trainer.evaluate()\n",
    "    print(\"Evaluation Results:\", results)\n",
    "    return model, trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainer, test_dataset):\n",
    "    \"\"\"Calculates accuracy and F1 score of the model.\"\"\"\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    preds = predictions.predictions.argmax(axis=-1)\n",
    "    labels = predictions.label_ids\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    return accuracy, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics for orientation-tr-train.tsv:\n",
      "label\n",
      "1    0.581856\n",
      "0    0.418144\n",
      "Name: proportion, dtype: float64\n",
      "Missing Value Check for orientation-tr-train.tsv:\n",
      "id         0\n",
      "speaker    0\n",
      "sex        0\n",
      "text       0\n",
      "text_en    0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "orientation_data = load_and_preprocess_data(\"orientation-tr-train.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution in Training Set:\n",
      "label\n",
      "1    0.581865\n",
      "0    0.418135\n",
      "Name: proportion, dtype: float64\n",
      "Class Distribution in Test Set:\n",
      "label\n",
      "1    0.581784\n",
      "0    0.418216\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "orientation_train, orientation_test = stratified_split(orientation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training set to orientation_train_processed.csv\n",
      "Saved test set to orientation_test_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Save processed datasets\n",
    "save_datasets(orientation_train, orientation_test, \"orientation_train_processed.csv\", \"orientation_test_processed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer setup\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0058005dbca246579a1dd3e72f0bf70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14524 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93096c497fa8463e90ed71b44474d14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare datasets for training\n",
    "orientation_train_dataset, orientation_test_dataset = prepare_datasets_for_training(orientation_train, orientation_test, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\rabai\\AppData\\Local\\Temp\\ipykernel_1804\\3073880974.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d762ae3a479e4e16ab137497d1a2ca5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2724 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6773, 'grad_norm': 1.002029299736023, 'learning_rate': 1.9632892804698974e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6604, 'grad_norm': 5.598144054412842, 'learning_rate': 1.9265785609397945e-05, 'epoch': 0.11}\n",
      "{'loss': 0.6692, 'grad_norm': 3.279832601547241, 'learning_rate': 1.8898678414096917e-05, 'epoch': 0.17}\n",
      "{'loss': 0.6804, 'grad_norm': 2.027076482772827, 'learning_rate': 1.853157121879589e-05, 'epoch': 0.22}\n",
      "{'loss': 0.6462, 'grad_norm': 3.1041321754455566, 'learning_rate': 1.816446402349486e-05, 'epoch': 0.28}\n",
      "{'loss': 0.6324, 'grad_norm': 3.934321165084839, 'learning_rate': 1.7797356828193833e-05, 'epoch': 0.33}\n",
      "{'loss': 0.5761, 'grad_norm': 7.792826175689697, 'learning_rate': 1.7430249632892805e-05, 'epoch': 0.39}\n",
      "{'loss': 0.6047, 'grad_norm': 3.529942274093628, 'learning_rate': 1.7063142437591777e-05, 'epoch': 0.44}\n",
      "{'loss': 0.5381, 'grad_norm': 8.477499008178711, 'learning_rate': 1.6696035242290752e-05, 'epoch': 0.5}\n",
      "{'loss': 0.5527, 'grad_norm': 8.729421615600586, 'learning_rate': 1.6328928046989724e-05, 'epoch': 0.55}\n",
      "{'loss': 0.5784, 'grad_norm': 5.592719078063965, 'learning_rate': 1.5961820851688693e-05, 'epoch': 0.61}\n",
      "{'loss': 0.5353, 'grad_norm': 8.66030216217041, 'learning_rate': 1.5594713656387664e-05, 'epoch': 0.66}\n",
      "{'loss': 0.5705, 'grad_norm': 4.073907375335693, 'learning_rate': 1.522760646108664e-05, 'epoch': 0.72}\n",
      "{'loss': 0.5545, 'grad_norm': 15.119170188903809, 'learning_rate': 1.486049926578561e-05, 'epoch': 0.77}\n",
      "{'loss': 0.5697, 'grad_norm': 9.172392845153809, 'learning_rate': 1.4493392070484582e-05, 'epoch': 0.83}\n",
      "{'loss': 0.5067, 'grad_norm': 11.167641639709473, 'learning_rate': 1.4126284875183555e-05, 'epoch': 0.88}\n",
      "{'loss': 0.5509, 'grad_norm': 6.311657428741455, 'learning_rate': 1.3759177679882527e-05, 'epoch': 0.94}\n",
      "{'loss': 0.5206, 'grad_norm': 11.476175308227539, 'learning_rate': 1.33920704845815e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf186685f375427cbdd2a32b2a934429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5300309062004089, 'eval_runtime': 13.5065, 'eval_samples_per_second': 119.498, 'eval_steps_per_second': 7.478, 'epoch': 1.0}\n",
      "{'loss': 0.4917, 'grad_norm': 7.45496129989624, 'learning_rate': 1.302496328928047e-05, 'epoch': 1.05}\n",
      "{'loss': 0.4985, 'grad_norm': 6.349391460418701, 'learning_rate': 1.2657856093979443e-05, 'epoch': 1.1}\n",
      "{'loss': 0.4859, 'grad_norm': 7.028117656707764, 'learning_rate': 1.2290748898678415e-05, 'epoch': 1.16}\n",
      "{'loss': 0.4648, 'grad_norm': 6.146389961242676, 'learning_rate': 1.1923641703377387e-05, 'epoch': 1.21}\n",
      "{'loss': 0.4128, 'grad_norm': 8.85926342010498, 'learning_rate': 1.155653450807636e-05, 'epoch': 1.27}\n",
      "{'loss': 0.4867, 'grad_norm': 8.730701446533203, 'learning_rate': 1.1189427312775332e-05, 'epoch': 1.32}\n",
      "{'loss': 0.4321, 'grad_norm': 11.654152870178223, 'learning_rate': 1.0822320117474303e-05, 'epoch': 1.38}\n",
      "{'loss': 0.4368, 'grad_norm': 7.543253421783447, 'learning_rate': 1.0455212922173275e-05, 'epoch': 1.43}\n",
      "{'loss': 0.4004, 'grad_norm': 9.698877334594727, 'learning_rate': 1.0088105726872248e-05, 'epoch': 1.49}\n",
      "{'loss': 0.435, 'grad_norm': 17.16560935974121, 'learning_rate': 9.72099853157122e-06, 'epoch': 1.54}\n",
      "{'loss': 0.4168, 'grad_norm': 8.584261894226074, 'learning_rate': 9.353891336270192e-06, 'epoch': 1.6}\n",
      "{'loss': 0.4736, 'grad_norm': 13.552474021911621, 'learning_rate': 8.986784140969164e-06, 'epoch': 1.65}\n",
      "{'loss': 0.4135, 'grad_norm': 9.893299102783203, 'learning_rate': 8.619676945668136e-06, 'epoch': 1.71}\n",
      "{'loss': 0.4661, 'grad_norm': 6.7075629234313965, 'learning_rate': 8.252569750367108e-06, 'epoch': 1.76}\n",
      "{'loss': 0.4457, 'grad_norm': 12.096183776855469, 'learning_rate': 7.88546255506608e-06, 'epoch': 1.82}\n",
      "{'loss': 0.4461, 'grad_norm': 8.934304237365723, 'learning_rate': 7.5183553597650514e-06, 'epoch': 1.87}\n",
      "{'loss': 0.4156, 'grad_norm': 11.14818286895752, 'learning_rate': 7.151248164464024e-06, 'epoch': 1.93}\n",
      "{'loss': 0.4242, 'grad_norm': 9.286918640136719, 'learning_rate': 6.784140969162997e-06, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba665049b904cabb5ca2453eb85dd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47719788551330566, 'eval_runtime': 13.5871, 'eval_samples_per_second': 118.789, 'eval_steps_per_second': 7.434, 'epoch': 2.0}\n",
      "{'loss': 0.3583, 'grad_norm': 8.75990104675293, 'learning_rate': 6.417033773861968e-06, 'epoch': 2.04}\n",
      "{'loss': 0.3399, 'grad_norm': 11.200645446777344, 'learning_rate': 6.049926578560941e-06, 'epoch': 2.09}\n",
      "{'loss': 0.3754, 'grad_norm': 10.269316673278809, 'learning_rate': 5.682819383259912e-06, 'epoch': 2.15}\n",
      "{'loss': 0.3442, 'grad_norm': 6.831853866577148, 'learning_rate': 5.3157121879588845e-06, 'epoch': 2.2}\n",
      "{'loss': 0.3268, 'grad_norm': 6.2501702308654785, 'learning_rate': 4.9486049926578564e-06, 'epoch': 2.26}\n",
      "{'loss': 0.3294, 'grad_norm': 20.18618392944336, 'learning_rate': 4.581497797356828e-06, 'epoch': 2.31}\n",
      "{'loss': 0.3316, 'grad_norm': 2.5683176517486572, 'learning_rate': 4.2143906020558e-06, 'epoch': 2.37}\n",
      "{'loss': 0.3499, 'grad_norm': 4.6725897789001465, 'learning_rate': 3.847283406754773e-06, 'epoch': 2.42}\n",
      "{'loss': 0.3415, 'grad_norm': 13.784618377685547, 'learning_rate': 3.4801762114537445e-06, 'epoch': 2.48}\n",
      "{'loss': 0.3293, 'grad_norm': 13.69848346710205, 'learning_rate': 3.113069016152717e-06, 'epoch': 2.53}\n",
      "{'loss': 0.3507, 'grad_norm': 8.102289199829102, 'learning_rate': 2.745961820851689e-06, 'epoch': 2.59}\n",
      "{'loss': 0.3398, 'grad_norm': 4.941840648651123, 'learning_rate': 2.378854625550661e-06, 'epoch': 2.64}\n",
      "{'loss': 0.3157, 'grad_norm': 17.63083267211914, 'learning_rate': 2.011747430249633e-06, 'epoch': 2.7}\n",
      "{'loss': 0.3242, 'grad_norm': 6.005466461181641, 'learning_rate': 1.644640234948605e-06, 'epoch': 2.75}\n",
      "{'loss': 0.3391, 'grad_norm': 23.967876434326172, 'learning_rate': 1.2775330396475772e-06, 'epoch': 2.81}\n",
      "{'loss': 0.3291, 'grad_norm': 12.291970252990723, 'learning_rate': 9.104258443465493e-07, 'epoch': 2.86}\n",
      "{'loss': 0.3536, 'grad_norm': 11.837550163269043, 'learning_rate': 5.433186490455213e-07, 'epoch': 2.92}\n",
      "{'loss': 0.3196, 'grad_norm': 12.8117036819458, 'learning_rate': 1.7621145374449343e-07, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59611f840bda46e299b842b9f69ebf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48130175471305847, 'eval_runtime': 13.583, 'eval_samples_per_second': 118.825, 'eval_steps_per_second': 7.436, 'epoch': 3.0}\n",
      "{'train_runtime': 2099.6034, 'train_samples_per_second': 20.752, 'train_steps_per_second': 1.297, 'train_loss': 0.4575502054981898, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4729609166bc475ea9514f4e4e6b4b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.47719788551330566, 'eval_runtime': 13.7051, 'eval_samples_per_second': 117.766, 'eval_steps_per_second': 7.369, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36eb5388c64840eca60fffddd5a984c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7862\n",
      "F1 Score: 0.7851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7862453531598513, 0.7851214744524638)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "model, trainer = train_model(orientation_train_dataset, orientation_test_dataset, tokenizer)\n",
    "evaluate_model(trainer, orientation_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./task1_multilingual_bert\")\n",
    "tokenizer.save_pretrained(\"./task1_multilingual_bert\")\n",
    "print(\"Model and tokenizer saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load required libraries\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load the test dataset\n",
    "orientation_test = pd.read_csv(\"orientation_test_processed.csv\")\n",
    "\n",
    "# Initialize the causal inference pipeline\n",
    "causal_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"bigscience/bloomz-1b1\",\n",
    "    device=0  # Use GPU for inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit input text to the first 500 characters to reduce memory usage\n",
    "def limit_text_length(dataset, column_name=\"text\"):\n",
    "    return dataset.map(lambda x: {column_name: x[column_name][:500]})\n",
    "\n",
    "# Generate prompts and perform inference in batches\n",
    "def generate_texts(batch, column_name=\"text\", prompt_template=\"Classify the text\"):\n",
    "    prompts = [prompt_template.format(text=text) for text in batch[column_name]]\n",
    "    outputs = causal_pipeline(prompts, max_new_tokens=10)\n",
    "    return {\"predictions\": [output[0][\"generated_text\"].strip() for output in outputs]}\n",
    "\n",
    "# Process predictions into binary labels\n",
    "def process_predictions(predictions):\n",
    "    binary_results = []\n",
    "    for pred in predictions:\n",
    "        if \"0\" in pred:\n",
    "            binary_results.append(0)\n",
    "        elif \"1\" in pred:\n",
    "            binary_results.append(1)\n",
    "        else:\n",
    "            binary_results.append(None)  # Model uncertain\n",
    "    return binary_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae18ad2f8b741c78f36d3b7ca33c4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd72816f54fb4ff5acef81669c2aa4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot Inference Accuracy (Turkish): 41.82%\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataset to HuggingFace Dataset format\n",
    "turkish_test_dataset = Dataset.from_pandas(orientation_test)\n",
    "\n",
    "# Limit text length for Turkish column\n",
    "turkish_test_dataset = limit_text_length(turkish_test_dataset, column_name=\"text\")\n",
    "\n",
    "# Define the Turkish prompt\n",
    "turkish_prompt = \"Aşağıdaki meclis konuşmasına dayanarak, konuşmacının partisinin sol (0) ya da sağ (1) eğilimli olduğunu belirtiniz:\\n\\n{text}\\n\\nCevap:\"\n",
    "\n",
    "# Perform inference\n",
    "results_turkish = turkish_test_dataset.map(\n",
    "    lambda batch: generate_texts(batch, column_name=\"text\", prompt_template=turkish_prompt),\n",
    "    batched=True,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# Process binary predictions for Turkish texts\n",
    "binary_predictions_turkish = process_predictions(results_turkish[\"predictions\"])\n",
    "results_turkish = results_turkish.add_column(\"binary_predictions\", binary_predictions_turkish)\n",
    "\n",
    "# Calculate accuracy for Turkish predictions\n",
    "correct_predictions_turkish = [\n",
    "    binary == label for binary, label in zip(results_turkish[\"binary_predictions\"], results_turkish[\"label\"])\n",
    "]\n",
    "accuracy_turkish = sum(correct_predictions_turkish) / len(correct_predictions_turkish)\n",
    "\n",
    "# Save results to CSV\n",
    "results_turkish_df = results_turkish.to_pandas()\n",
    "results_turkish_df.to_csv(\"task1_bloomz_turkish_results_binary.csv\", index=False)\n",
    "\n",
    "print(f\"Zero-Shot Inference Accuracy (Turkish): {accuracy_turkish:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c045aa68e80f49c086959720c9c6c7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664c3e917b394451b27e3034c3b9f360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot Inference Accuracy (English): 41.82%\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataset to HuggingFace Dataset format\n",
    "english_test_dataset = Dataset.from_pandas(orientation_test)\n",
    "\n",
    "# Limit text length for English column\n",
    "english_test_dataset = limit_text_length(english_test_dataset, column_name=\"text_en\")\n",
    "\n",
    "# Define the English prompt\n",
    "english_prompt = \"Based on the following parliamentary speech, classify whether the speaker's party leans left (0) or right (1):\\n\\n{text}\\n\\nAnswer:\"\n",
    "\n",
    "# Perform inference\n",
    "results_english = english_test_dataset.map(\n",
    "    lambda batch: generate_texts(batch, column_name=\"text_en\", prompt_template=english_prompt),\n",
    "    batched=True,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# Process binary predictions for English texts\n",
    "binary_predictions_english = process_predictions(results_english[\"predictions\"])\n",
    "results_english = results_english.add_column(\"binary_predictions\", binary_predictions_english)\n",
    "\n",
    "# Calculate accuracy for English predictions\n",
    "correct_predictions_english = [\n",
    "    binary == label for binary, label in zip(results_english[\"binary_predictions\"], results_english[\"label\"])\n",
    "]\n",
    "accuracy_english = sum(correct_predictions_english) / len(correct_predictions_english)\n",
    "\n",
    "# Save results to CSV\n",
    "results_english_df = results_english.to_pandas()\n",
    "results_english_df.to_csv(\"task1_bloomz_english_results_binary.csv\", index=False)\n",
    "\n",
    "print(f\"Zero-Shot Inference Accuracy (English): {accuracy_english:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
