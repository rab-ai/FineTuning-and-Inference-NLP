{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import transformers\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "MAX_LENGTH = 128\n",
    "TRAIN_TEST_SPLIT_RATIO = 0.1\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(filepath, drop_na=True):\n",
    "    \"\"\"Loads data, checks for missing values, and optionally drops missing rows.\"\"\"\n",
    "    data = pd.read_csv(filepath, sep='\\t')\n",
    "    print(f\"Dataset Statistics for {filepath}:\")\n",
    "    print(data['label'].value_counts(normalize=True))\n",
    "    print(f\"Missing Value Check for {filepath}:\")\n",
    "    print(data.isnull().sum())\n",
    "    if drop_na:\n",
    "        data = data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(data, test_size=TRAIN_TEST_SPLIT_RATIO, random_state=RANDOM_STATE):\n",
    "    \"\"\"Splits the dataset into training and test sets with stratification.\"\"\"\n",
    "    train, test = train_test_split(\n",
    "        data,\n",
    "        test_size=test_size,\n",
    "        stratify=data['label'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    print(\"Class Distribution in Training Set:\")\n",
    "    print(train['label'].value_counts(normalize=True))\n",
    "    print(\"Class Distribution in Test Set:\")\n",
    "    print(test['label'].value_counts(normalize=True))\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_datasets(train, test, train_filepath, test_filepath):\n",
    "    \"\"\"Saves the training and test sets to CSV files.\"\"\"\n",
    "    train.to_csv(train_filepath, index=False)\n",
    "    test.to_csv(test_filepath, index=False)\n",
    "    print(f\"Saved training set to {train_filepath}\")\n",
    "    print(f\"Saved test set to {test_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets_for_training(train_data, test_data, tokenizer):\n",
    "    \"\"\"Tokenizes the data and prepares it for training.\"\"\"\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text_en\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_data).map(tokenize_function, batched=True)\n",
    "    test_dataset = Dataset.from_pandas(test_data).map(tokenize_function, batched=True)\n",
    "\n",
    "    train_dataset = train_dataset.remove_columns([\"id\", \"speaker\", \"sex\", \"text\", \"text_en\"])\n",
    "    test_dataset = test_dataset.remove_columns([\"id\", \"speaker\", \"sex\", \"text\", \"text_en\"])\n",
    "\n",
    "    train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "    test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "    train_dataset.set_format(\"torch\")\n",
    "    test_dataset.set_format(\"torch\")\n",
    "\n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataset, test_dataset, tokenizer):\n",
    "    \"\"\"Trains a BERT model and evaluates it.\"\"\"\n",
    "    model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results_task2\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=50\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    results = trainer.evaluate()\n",
    "    print(\"Evaluation Results:\", results)\n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainer, test_dataset):\n",
    "    \"\"\"Calculates accuracy and F1 score of the model.\"\"\"\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    preds = predictions.predictions.argmax(axis=-1)\n",
    "    labels = predictions.label_ids\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics for power-tr-train.tsv:\n",
      "label\n",
      "1    0.513806\n",
      "0    0.486194\n",
      "Name: proportion, dtype: float64\n",
      "Missing Value Check for power-tr-train.tsv:\n",
      "id         0\n",
      "speaker    0\n",
      "sex        0\n",
      "text       0\n",
      "text_en    0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "power_data = load_and_preprocess_data(\"power-tr-train.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution in Training Set:\n",
      "label\n",
      "1    0.513774\n",
      "0    0.486226\n",
      "Name: proportion, dtype: float64\n",
      "Class Distribution in Test Set:\n",
      "label\n",
      "1    0.514089\n",
      "0    0.485911\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "power_train, power_test = stratified_split(power_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training set to power_train_processed.csv\n",
      "Saved test set to power_test_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Save processed datasets\n",
    "save_datasets(power_train, power_test, \"power_train_processed.csv\", \"power_test_processed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer setup\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fcc6221d224a608f1416eaa1c577d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15645 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fe1a2fac274d2f98ffc3c08b8a8010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1739 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare datasets for training\n",
    "power_train_dataset, power_test_dataset = prepare_datasets_for_training(power_train, power_test, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\rabai\\AppData\\Local\\Temp\\ipykernel_23400\\1560980363.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eea6f0e3ef8488fbec3b48ccfb5d81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2934 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6978, 'grad_norm': 1.3391704559326172, 'learning_rate': 1.9659168370824816e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6521, 'grad_norm': 4.183454990386963, 'learning_rate': 1.9318336741649627e-05, 'epoch': 0.1}\n",
      "{'loss': 0.6196, 'grad_norm': 3.2177321910858154, 'learning_rate': 1.8977505112474438e-05, 'epoch': 0.15}\n",
      "{'loss': 0.5913, 'grad_norm': 5.108887195587158, 'learning_rate': 1.8636673483299253e-05, 'epoch': 0.2}\n",
      "{'loss': 0.5671, 'grad_norm': 10.113988876342773, 'learning_rate': 1.8295841854124064e-05, 'epoch': 0.26}\n",
      "{'loss': 0.5312, 'grad_norm': 7.7452616691589355, 'learning_rate': 1.795501022494888e-05, 'epoch': 0.31}\n",
      "{'loss': 0.5617, 'grad_norm': 6.042710304260254, 'learning_rate': 1.761417859577369e-05, 'epoch': 0.36}\n",
      "{'loss': 0.4899, 'grad_norm': 5.283132076263428, 'learning_rate': 1.72733469665985e-05, 'epoch': 0.41}\n",
      "{'loss': 0.5376, 'grad_norm': 7.643433094024658, 'learning_rate': 1.6932515337423315e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4834, 'grad_norm': 8.389946937561035, 'learning_rate': 1.6591683708248126e-05, 'epoch': 0.51}\n",
      "{'loss': 0.514, 'grad_norm': 5.100094318389893, 'learning_rate': 1.6250852079072937e-05, 'epoch': 0.56}\n",
      "{'loss': 0.4824, 'grad_norm': 4.297148704528809, 'learning_rate': 1.591002044989775e-05, 'epoch': 0.61}\n",
      "{'loss': 0.4833, 'grad_norm': 6.9862260818481445, 'learning_rate': 1.5569188820722566e-05, 'epoch': 0.66}\n",
      "{'loss': 0.493, 'grad_norm': 4.439032554626465, 'learning_rate': 1.5228357191547376e-05, 'epoch': 0.72}\n",
      "{'loss': 0.4786, 'grad_norm': 5.448586463928223, 'learning_rate': 1.488752556237219e-05, 'epoch': 0.77}\n",
      "{'loss': 0.4903, 'grad_norm': 9.655645370483398, 'learning_rate': 1.4546693933197003e-05, 'epoch': 0.82}\n",
      "{'loss': 0.4608, 'grad_norm': 4.78670072555542, 'learning_rate': 1.4205862304021814e-05, 'epoch': 0.87}\n",
      "{'loss': 0.4443, 'grad_norm': 6.186481952667236, 'learning_rate': 1.3865030674846627e-05, 'epoch': 0.92}\n",
      "{'loss': 0.4289, 'grad_norm': 4.686895847320557, 'learning_rate': 1.352419904567144e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e66ed0c45a4588bf772681c6ed9a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4340490400791168, 'eval_runtime': 14.8085, 'eval_samples_per_second': 117.433, 'eval_steps_per_second': 7.361, 'epoch': 1.0}\n",
      "{'loss': 0.4283, 'grad_norm': 6.718875408172607, 'learning_rate': 1.318336741649625e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3821, 'grad_norm': 15.446608543395996, 'learning_rate': 1.2842535787321065e-05, 'epoch': 1.07}\n",
      "{'loss': 0.3745, 'grad_norm': 4.825876235961914, 'learning_rate': 1.2501704158145878e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3721, 'grad_norm': 11.287981986999512, 'learning_rate': 1.2160872528970689e-05, 'epoch': 1.18}\n",
      "{'loss': 0.3524, 'grad_norm': 10.542778015136719, 'learning_rate': 1.1820040899795502e-05, 'epoch': 1.23}\n",
      "{'loss': 0.3744, 'grad_norm': 10.010162353515625, 'learning_rate': 1.1479209270620315e-05, 'epoch': 1.28}\n",
      "{'loss': 0.3746, 'grad_norm': 6.4129228591918945, 'learning_rate': 1.1138377641445126e-05, 'epoch': 1.33}\n",
      "{'loss': 0.3448, 'grad_norm': 7.605463981628418, 'learning_rate': 1.079754601226994e-05, 'epoch': 1.38}\n",
      "{'loss': 0.3424, 'grad_norm': 9.722461700439453, 'learning_rate': 1.0456714383094753e-05, 'epoch': 1.43}\n",
      "{'loss': 0.3616, 'grad_norm': 11.658703804016113, 'learning_rate': 1.0115882753919564e-05, 'epoch': 1.48}\n",
      "{'loss': 0.3241, 'grad_norm': 19.699098587036133, 'learning_rate': 9.775051124744377e-06, 'epoch': 1.53}\n",
      "{'loss': 0.3902, 'grad_norm': 19.397966384887695, 'learning_rate': 9.43421949556919e-06, 'epoch': 1.58}\n",
      "{'loss': 0.3843, 'grad_norm': 6.770761489868164, 'learning_rate': 9.093387866394002e-06, 'epoch': 1.64}\n",
      "{'loss': 0.3204, 'grad_norm': 12.107854843139648, 'learning_rate': 8.752556237218815e-06, 'epoch': 1.69}\n",
      "{'loss': 0.322, 'grad_norm': 8.169734954833984, 'learning_rate': 8.411724608043628e-06, 'epoch': 1.74}\n",
      "{'loss': 0.3616, 'grad_norm': 6.367907524108887, 'learning_rate': 8.070892978868439e-06, 'epoch': 1.79}\n",
      "{'loss': 0.3498, 'grad_norm': 9.40942668914795, 'learning_rate': 7.730061349693252e-06, 'epoch': 1.84}\n",
      "{'loss': 0.3841, 'grad_norm': 7.38999080657959, 'learning_rate': 7.389229720518065e-06, 'epoch': 1.89}\n",
      "{'loss': 0.3392, 'grad_norm': 4.832126617431641, 'learning_rate': 7.048398091342877e-06, 'epoch': 1.94}\n",
      "{'loss': 0.3196, 'grad_norm': 13.264775276184082, 'learning_rate': 6.707566462167689e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57fbb9a60cf4d3dab3d52eb9cfe67ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4357866942882538, 'eval_runtime': 14.7162, 'eval_samples_per_second': 118.169, 'eval_steps_per_second': 7.407, 'epoch': 2.0}\n",
      "{'loss': 0.2945, 'grad_norm': 6.184322834014893, 'learning_rate': 6.366734832992503e-06, 'epoch': 2.04}\n",
      "{'loss': 0.2377, 'grad_norm': 6.779289722442627, 'learning_rate': 6.025903203817315e-06, 'epoch': 2.1}\n",
      "{'loss': 0.2449, 'grad_norm': 8.739617347717285, 'learning_rate': 5.685071574642127e-06, 'epoch': 2.15}\n",
      "{'loss': 0.2649, 'grad_norm': 14.639701843261719, 'learning_rate': 5.3442399454669404e-06, 'epoch': 2.2}\n",
      "{'loss': 0.2726, 'grad_norm': 7.447010040283203, 'learning_rate': 5.003408316291752e-06, 'epoch': 2.25}\n",
      "{'loss': 0.2405, 'grad_norm': 10.573034286499023, 'learning_rate': 4.662576687116564e-06, 'epoch': 2.3}\n",
      "{'loss': 0.2668, 'grad_norm': 9.638249397277832, 'learning_rate': 4.321745057941377e-06, 'epoch': 2.35}\n",
      "{'loss': 0.239, 'grad_norm': 8.02473258972168, 'learning_rate': 3.98091342876619e-06, 'epoch': 2.4}\n",
      "{'loss': 0.2478, 'grad_norm': 5.467612266540527, 'learning_rate': 3.6400817995910027e-06, 'epoch': 2.45}\n",
      "{'loss': 0.2066, 'grad_norm': 10.068446159362793, 'learning_rate': 3.2992501704158146e-06, 'epoch': 2.51}\n",
      "{'loss': 0.2764, 'grad_norm': 10.72965145111084, 'learning_rate': 2.9584185412406274e-06, 'epoch': 2.56}\n",
      "{'loss': 0.2204, 'grad_norm': 9.397408485412598, 'learning_rate': 2.61758691206544e-06, 'epoch': 2.61}\n",
      "{'loss': 0.243, 'grad_norm': 7.648974418640137, 'learning_rate': 2.276755282890252e-06, 'epoch': 2.66}\n",
      "{'loss': 0.2545, 'grad_norm': 7.730958938598633, 'learning_rate': 1.935923653715065e-06, 'epoch': 2.71}\n",
      "{'loss': 0.2246, 'grad_norm': 17.306442260742188, 'learning_rate': 1.5950920245398775e-06, 'epoch': 2.76}\n",
      "{'loss': 0.2062, 'grad_norm': 6.329063892364502, 'learning_rate': 1.25426039536469e-06, 'epoch': 2.81}\n",
      "{'loss': 0.2377, 'grad_norm': 18.959396362304688, 'learning_rate': 9.134287661895025e-07, 'epoch': 2.86}\n",
      "{'loss': 0.2213, 'grad_norm': 7.433547019958496, 'learning_rate': 5.72597137014315e-07, 'epoch': 2.91}\n",
      "{'loss': 0.235, 'grad_norm': 11.995397567749023, 'learning_rate': 2.317655078391275e-07, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e9dfd599a44e59861e6816b3f7922d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5161563754081726, 'eval_runtime': 14.8866, 'eval_samples_per_second': 116.816, 'eval_steps_per_second': 7.322, 'epoch': 3.0}\n",
      "{'train_runtime': 8151.3009, 'train_samples_per_second': 5.758, 'train_steps_per_second': 0.36, 'train_loss': 0.3748231405454504, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2f51d1d4f0429eab1e3aa3d1394495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.4340490400791168, 'eval_runtime': 15.1618, 'eval_samples_per_second': 114.696, 'eval_steps_per_second': 7.189, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94303b79e9c411f8fa3ea4a513925b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7918\n",
      "F1 Score: 0.7913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7918343875790684, 0.7912730486144101)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "model, trainer = train_model(power_train_dataset, power_test_dataset, tokenizer)\n",
    "evaluate_model(trainer, power_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./task2_multilingual_bert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./task2_multilingual_bert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel and tokenizer saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./task2_multilingual_bert\")\n",
    "tokenizer.save_pretrained(\"./task2_multilingual_bert\")\n",
    "print(\"Model and tokenizer saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load required libraries\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load the test dataset for Task 2\n",
    "power_test = pd.read_csv(\"power_test_processed.csv\")\n",
    "\n",
    "# Initialize the causal inference pipeline\n",
    "causal_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"bigscience/bloomz-1b1\",\n",
    "    device=0  # Use GPU for inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit input text to the first 500 characters to reduce memory usage\n",
    "def limit_text_length(dataset, column_name=\"text_en\"):\n",
    "    return dataset.map(lambda x: {column_name: x[column_name][:500]})\n",
    "\n",
    "# Generate prompts and perform inference in batches\n",
    "def generate_texts(batch, column_name=\"text_en\", prompt_template=\"Classify the text\"):\n",
    "    prompts = [prompt_template.format(text=text) for text in batch[column_name]]\n",
    "    outputs = causal_pipeline(prompts, max_new_tokens=10)\n",
    "    return {\"predictions\": [output[0][\"generated_text\"].strip() for output in outputs]}\n",
    "\n",
    "# Process predictions into binary labels\n",
    "def process_predictions(predictions):\n",
    "    binary_results = []\n",
    "    for pred in predictions:\n",
    "        if \"0\" in pred:\n",
    "            binary_results.append(0)\n",
    "        elif \"1\" in pred:\n",
    "            binary_results.append(1)\n",
    "        else:\n",
    "            binary_results.append(None)  # Model uncertain\n",
    "    return binary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to HuggingFace Dataset format\n",
    "turkish_test_dataset = Dataset.from_pandas(power_test)\n",
    "\n",
    "# Limit text length for Turkish column\n",
    "turkish_test_dataset = limit_text_length(turkish_test_dataset, column_name=\"text\")\n",
    "\n",
    "# Define the Turkish prompt\n",
    "turkish_prompt = \"Aşağıdaki meclis konuşmasına dayanarak, konuşmacının partisinin hükümette (0) ya da muhalefette (1) olduğunu belirtiniz:\\n\\n{text}\\n\\nCevap:\"\n",
    "\n",
    "# Perform inference\n",
    "results_turkish = turkish_test_dataset.map(\n",
    "    lambda batch: generate_texts(batch, column_name=\"text\", prompt_template=turkish_prompt),\n",
    "    batched=True,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# Process binary predictions for Turkish texts\n",
    "binary_predictions_turkish = process_predictions(results_turkish[\"predictions\"])\n",
    "results_turkish = results_turkish.add_column(\"binary_predictions\", binary_predictions_turkish)\n",
    "\n",
    "# Calculate accuracy for Turkish predictions\n",
    "correct_predictions_turkish = [\n",
    "    binary == label for binary, label in zip(results_turkish[\"binary_predictions\"], results_turkish[\"label\"])\n",
    "]\n",
    "accuracy_turkish = sum(correct_predictions_turkish) / len(correct_predictions_turkish)\n",
    "\n",
    "# Save results to CSV\n",
    "results_turkish_df = results_turkish.to_pandas()\n",
    "results_turkish_df.to_csv(\"task2_bloomz_turkish_results_binary.csv\", index=False)\n",
    "\n",
    "print(f\"Zero-Shot Inference Accuracy (Turkish - Task 2): {accuracy_turkish:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to HuggingFace Dataset format\n",
    "english_test_dataset = Dataset.from_pandas(power_test)\n",
    "\n",
    "# Limit text length for English column\n",
    "english_test_dataset = limit_text_length(english_test_dataset, column_name=\"text_en\")\n",
    "\n",
    "# Define the English prompt\n",
    "english_prompt = \"Based on the following parliamentary speech, classify whether the speaker's party is governing (0) or opposition (1):\\n\\n{text}\\n\\nAnswer:\"\n",
    "\n",
    "# Perform inference\n",
    "results_english = english_test_dataset.map(\n",
    "    lambda batch: generate_texts(batch, column_name=\"text_en\", prompt_template=english_prompt),\n",
    "    batched=True,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# Process binary predictions for English texts\n",
    "binary_predictions_english = process_predictions(results_english[\"predictions\"])\n",
    "results_english = results_english.add_column(\"binary_predictions\", binary_predictions_english)\n",
    "\n",
    "# Calculate accuracy for English predictions\n",
    "correct_predictions_english = [\n",
    "    binary == label for binary, label in zip(results_english[\"binary_predictions\"], results_english[\"label\"])\n",
    "]\n",
    "accuracy_english = sum(correct_predictions_english) / len(correct_predictions_english)\n",
    "\n",
    "# Save results to CSV\n",
    "results_english_df = results_english.to_pandas()\n",
    "results_english_df.to_csv(\"task2_bloomz_english_results_binary.csv\", index=False)\n",
    "\n",
    "print(f\"Zero-Shot Inference Accuracy (English - Task 2): {accuracy_english:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
